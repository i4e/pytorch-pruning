{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実装説明\n",
    "\n",
    "1 iterのpruningを通して実装を理解します\n",
    "\n",
    "- 元論文 [1611.06440 Pruning Convolutional Neural Networks for Resource Efficient Inference](https://arxiv.org/abs/1611.06440)\n",
    "- [pytorchでの実装](https://github.com/jacobgil/pytorch-pruning)\n",
    "- [実装者によるブログ記事](https://jacobgil.github.io/deeplearning/pruning-deep-learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装のキモは以下の2点です\n",
    "- 各フィルタの重要度の計算\n",
    "- 重要度が最も低いn枚のフィルタを削除した新たなネットワークの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import dataset\n",
    "from prune import *\n",
    "import argparse\n",
    "from operator import itemgetter\n",
    "from heapq import nsmallest\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pruningしたい学習済みモデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<module '__main__'> is a built-in class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c152ff9f29dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Ignore containers that don't have any sources saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0m_check_container_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtypename\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'storage'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_container_source\u001b[0;34m(container_type, source_file, original_source)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_container_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mcurrent_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moriginal_source\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcurrent_source\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontainer_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_patches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     OSError is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m--> 949\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    934\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    935\u001b[0m     \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    747\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0midentified\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZED_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is a built-in class'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <module '__main__'> is a built-in class"
     ]
    }
   ],
   "source": [
    "class ModifiedVGG16Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedVGG16Model, self).__init__()\n",
    "\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        self.features = model.features\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = torch.load(\"model\").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※上記でエラーが起こる場合，別のファイルからクラスをインポートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune import ModifiedVGG16Model\n",
    "model = torch.load(\"model\").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本実装では，フォーク元(https://jacobgil.github.io/deeplearning/pruning-deep-learning) と同様に以下のデータを使用します。\n",
    "- 犬猫の2クラス分類のデータセット(https://www.kaggle.com/c/dogs-vs-cats)\n",
    "- トレーニングデータ1000枚ずつ，テストデータ400枚ずつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train\"\n",
    "test_path = \"test\"\n",
    "\n",
    "train_data_loader = dataset.loader(train_path)\n",
    "test_data_loader = dataset.test_loader(test_path)\n",
    "\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各フィルタの重要度を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各フィルタの重要度`grad*activation`を計算し、辞書`filter_ranks`に保存します。\n",
    "\n",
    "`register_hook`を用いて、backwardの際に重要度を計算するようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配と特徴マップからフィルタの重要度を返す関数\n",
    "`register_hook`に渡す関数は以下です。（解説は後述）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for register_hook\n",
    "# compute grad*activation\n",
    "def compute_rank(grad):\n",
    "    global grad_index\n",
    "    global activations\n",
    "    global filter_ranks\n",
    "    activation_index = len(activations) - grad_index - 1\n",
    "    activation = activations[activation_index]\n",
    "\n",
    "    values = torch.sum((activation * grad), dim = 0, keepdim=True).sum(dim=2, keepdim=True).sum(dim=3, keepdim=True)[0, :, 0, 0].data\n",
    "\n",
    "    # Normalize the rank by the filter dimensions\n",
    "    values = values / (activation.size(0) * activation.size(2) * activation.size(3))\n",
    "\n",
    "    if activation_index not in filter_ranks:\n",
    "        filter_ranks[activation_index] = torch.FloatTensor(activation.size(1)).zero_().cuda()\n",
    "\n",
    "    filter_ranks[activation_index] += values\n",
    "    grad_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィルタの重要度を計算するループ\n",
    "\n",
    "フィルタの重要度を計算します。\n",
    "- 順伝播の際に`activation`を記録、各層の出力`x`に`compute_rank`のフックを登録\n",
    "- 逆伝播の際に`compute_rank`が呼び出され`grad*activation`を計算、`filter_ranks`に保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# dictonary storing importances of each filter\n",
    "filter_ranks = {}\n",
    "\n",
    "# back propagation loop computing importances\n",
    "for batch, label in train_data_loader:\n",
    "    model.zero_grad()\n",
    "    x = Variable(batch.cuda(), requires_grad = True)\n",
    "\n",
    "    activations = []\n",
    "    grad_index = 0\n",
    "    activation_to_layer = {}\n",
    "    activation_index = 0\n",
    "\n",
    "    # forward\n",
    "    for layer, (name, module) in enumerate(model.features._modules.items()):\n",
    "        # print(\"layer, name, module: \", layer, name, module)\n",
    "\n",
    "        x = module(x)\n",
    "        \n",
    "        # store activation\n",
    "        if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "            x.register_hook(compute_rank)\n",
    "            activations.append(x)\n",
    "            activation_to_layer[activation_index] = layer\n",
    "            activation_index += 1\n",
    "\n",
    "    # print(x.data.cpu().numpy().shape)\n",
    "    out = model.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "    # backward, compute compute_rank()\n",
    "    # no update of weights\n",
    "    criterion(out, Variable(label.cuda())).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 少し詳しい説明\n",
    "上記のソースをもう少し詳しく解説します。\n",
    "\n",
    "順伝播では、元々のモデルのソースに変更を加えたくないため、`model.features._modules.items()`でモデルの各層を関数`module`として使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer, name, module:  0 0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  1 1 ReLU (inplace)\n",
      "layer, name, module:  2 2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  3 3 ReLU (inplace)\n",
      "layer, name, module:  4 4 MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "layer, name, module:  5 5 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  6 6 ReLU (inplace)\n",
      "layer, name, module:  7 7 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  8 8 ReLU (inplace)\n",
      "layer, name, module:  9 9 MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "layer, name, module:  10 10 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  11 11 ReLU (inplace)\n",
      "layer, name, module:  12 12 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  13 13 ReLU (inplace)\n",
      "layer, name, module:  14 14 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  15 15 ReLU (inplace)\n",
      "layer, name, module:  16 16 MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "layer, name, module:  17 17 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  18 18 ReLU (inplace)\n",
      "layer, name, module:  19 19 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  20 20 ReLU (inplace)\n",
      "layer, name, module:  21 21 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  22 22 ReLU (inplace)\n",
      "layer, name, module:  23 23 MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "layer, name, module:  24 24 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  25 25 ReLU (inplace)\n",
      "layer, name, module:  26 26 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  27 27 ReLU (inplace)\n",
      "layer, name, module:  28 28 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "layer, name, module:  29 29 ReLU (inplace)\n",
      "layer, name, module:  30 30 MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "for layer, (name, module) in enumerate(model.features._modules.items()):\n",
    "    print(\"layer, name, module: \", layer, name, module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter_ranksの中身を確認する\n",
    "`filter_ranks`は、各CONV層におけるフィルタの重要度を保存した辞書です。\n",
    "\n",
    "キーにはCONV層の番号(全体の層番号ではなく、何番目のCONV層か)、バリューには各層のフィルタ数と同サイズの配列が格納されます。たとえば以下を実行すると、2番目（3つ目）のCONV層の10番目のフィルタの重要度が確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.786516593138003e-08\n"
     ]
    }
   ],
   "source": [
    "print(filter_ranks[2][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全体を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64,) [ -3.73500662e-08  -2.04436663e-08  -4.24422844e-08   1.50498369e-09\n",
      "  -1.22746599e-07   1.56757203e-08  -7.06289285e-08  -1.56441722e-08\n",
      "   4.98041928e-08   6.61597568e-08]\n",
      "1 (64,) [ -6.03485262e-08   1.54667390e-08  -1.66291812e-07  -1.09614007e-09\n",
      "  -4.62700172e-08  -3.33858274e-08  -1.93150616e-08   1.03554010e-08\n",
      "  -5.13008942e-08  -4.12457482e-08]\n",
      "2 (128,) [  7.49703801e-08   1.48712473e-07  -2.28549837e-07  -1.70827221e-07\n",
      "  -3.12936493e-07  -2.63289213e-08  -2.85883104e-08  -1.14331733e-07\n",
      "  -2.27099548e-07  -3.41180915e-08]\n",
      "3 (128,) [  5.78968269e-08  -3.95947012e-07  -3.97092407e-07   3.17554111e-07\n",
      "   7.05701497e-09   2.53987679e-07  -2.54641233e-08   5.12535685e-08\n",
      "  -3.63208699e-08  -1.13324226e-07]\n",
      "4 (256,) [  8.22116363e-07  -1.80695736e-07  -2.16293529e-07   1.20318447e-07\n",
      "  -2.78650667e-08   3.89945178e-08  -2.46329193e-07   2.94861366e-07\n",
      "  -3.94033407e-07  -3.23816550e-07]\n",
      "5 (256,) [ -1.88000655e-07  -7.05653406e-07  -1.78253941e-07  -2.87118553e-07\n",
      "   1.47676253e-08  -8.08962284e-07   7.41267243e-08  -6.47802523e-08\n",
      "  -9.42650445e-07   3.66826896e-07]\n",
      "6 (256,) [ -1.84796690e-07  -2.70328258e-07  -2.81789852e-07  -1.09626865e-06\n",
      "  -3.09229421e-07  -8.16467747e-08  -5.75220099e-07  -1.16607389e-07\n",
      "   1.21896761e-07  -9.64820060e-07]\n",
      "7 (512,) [  6.66967253e-07  -7.56142185e-07  -1.35905026e-07  -1.18118214e-06\n",
      "  -5.31615513e-07   1.04317314e-06   2.35522634e-07   1.27652569e-07\n",
      "  -8.25799304e-07   1.54944019e-07]\n",
      "8 (512,) [  4.30816698e-07  -1.79872245e-07  -4.61390755e-06  -1.18717526e-06\n",
      "   5.99207453e-07  -2.23348337e-07   7.79191168e-07   1.82659505e-08\n",
      "  -3.88944318e-06   1.86445007e-07]\n",
      "9 (512,) [ -3.60778495e-06  -5.40017879e-07   1.03791353e-06  -3.20131051e-07\n",
      "  -1.15264629e-06   2.20790497e-07   1.43743591e-06  -9.15089515e-08\n",
      "   2.26433349e-06  -8.69056180e-07]\n",
      "10 (512,) [  1.43056968e-06   3.65088681e-07   1.32466744e-06   1.52440680e-06\n",
      "   7.40145481e-07   9.70512519e-06  -2.80355907e-05  -1.54471184e-06\n",
      "  -9.13983604e-06  -1.51265604e-05]\n",
      "11 (512,) [ -1.31713296e-06  -1.48420531e-06  -2.14270813e-06   2.85565147e-06\n",
      "   6.38635015e-07   3.45203898e-06  -1.21488642e-06   1.31672550e-06\n",
      "  -7.38950746e-07   1.21639937e-06]\n",
      "12 (512,) [ -1.42886040e-06   1.03877551e-06   1.62380638e-06  -1.57919458e-05\n",
      "  -4.68435815e-08   1.12217504e-06  -1.78906120e-07   2.08642541e-06\n",
      "   1.32535334e-07   5.82719224e-08]\n"
     ]
    }
   ],
   "source": [
    "for i in filter_ranks:\n",
    "    f = filter_ranks[i].cpu().numpy()\n",
    "    print(i, f.shape, f[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute_rankの動作内容を確認する\n",
    "\n",
    "`compute_rank`の動作を説明します。\n",
    "\n",
    "まず、順伝播によって計算されたある層のactivationを取得します。ここでは第2層とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 128, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "grad = 0.01\n",
    "activation_index = 2\n",
    "activation = activations[activation_index]\n",
    "print(activations[2].data.cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆伝播によって計算された勾配`grad`と各`activation`の要素積を取ります。\n",
    "ここでは簡単のため、`grad`の値は全て`0.0001`とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "grad = 0.0001\n",
    "\n",
    "product = activation * grad\n",
    "print(product.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チャンネル毎に要素を足し合わせます。各チャンネルに重要度の値がひとつずつある状態になりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3.9450\n",
      " 12.9920\n",
      " 15.2859\n",
      " 15.6443\n",
      " 16.1155\n",
      "  9.4931\n",
      "  6.8969\n",
      " 13.4246\n",
      " 12.3292\n",
      "  9.0060\n",
      "[torch.cuda.FloatTensor of size 10 (GPU 0)]\n",
      "\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "values = torch.sum(product, dim = 0, keepdim=True).sum(dim=2, keepdim=True).sum(dim=3, keepdim=True)[0, :, 0, 0].data\n",
    "\n",
    "print(values[:10])\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "足し合わせた数だけ値を割ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-05 *\n",
      "  1.9656\n",
      "  6.4732\n",
      "  7.6162\n",
      "  7.7947\n",
      "  8.0295\n",
      "  4.7299\n",
      "  3.4363\n",
      "  6.6887\n",
      "  6.1430\n",
      "  4.4872\n",
      "[torch.cuda.FloatTensor of size 10 (GPU 0)]\n",
      "\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Normalize the rank by the filter dimensions\n",
    "values = values / (activation.size(0) * activation.size(2) * activation.size(3))\n",
    "\n",
    "print(values[:10])\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このベクトルを、`filter_ranks[2]`のバリューに足し合わせます。\n",
    "ここでは、先程の計算結果に影響が出ないようダミーの`filter_ranks`を用います。\n",
    "以上がcompute_rankの動作説明です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: \n",
      "1.00000e-04 *\n",
      "  0.1966\n",
      "  0.6473\n",
      "  0.7616\n",
      "  0.7795\n",
      "  0.8029\n",
      "  0.4730\n",
      "  0.3436\n",
      "  0.6689\n",
      "  0.6143\n",
      "  0.4487\n",
      "  0.5297\n",
      "  0.9691\n",
      "  0.8908\n",
      "  0.4443\n",
      "  0.9500\n",
      "  0.6043\n",
      "  0.4370\n",
      "  0.8381\n",
      "  0.7852\n",
      "  0.8091\n",
      "  0.3340\n",
      "  0.7913\n",
      "  0.7001\n",
      "  0.7547\n",
      "  0.5177\n",
      "  0.8574\n",
      "  0.9816\n",
      "  0.8555\n",
      "  0.0756\n",
      "  0.4242\n",
      "  1.0942\n",
      "  1.0451\n",
      "  0.6496\n",
      "  0.8781\n",
      "  0.6409\n",
      "  1.2347\n",
      "  0.9718\n",
      "  1.0940\n",
      "  0.5992\n",
      "  0.3715\n",
      "  0.8031\n",
      "  0.4157\n",
      "  0.8682\n",
      "  0.9762\n",
      "  0.6648\n",
      "  0.5830\n",
      "  0.3536\n",
      "  0.9903\n",
      "  0.5256\n",
      "  0.8474\n",
      "  0.6614\n",
      "  0.5325\n",
      "  0.7867\n",
      "  0.9657\n",
      "  0.4549\n",
      "  0.9072\n",
      "  0.1479\n",
      "  0.9983\n",
      "  0.6620\n",
      "  0.7351\n",
      "  0.4536\n",
      "  0.7857\n",
      "  0.5795\n",
      "  0.7157\n",
      "  0.1190\n",
      "  0.7701\n",
      "  0.4999\n",
      "  0.4382\n",
      "  0.4138\n",
      "  0.2965\n",
      "  1.0581\n",
      "  0.7284\n",
      "  0.4779\n",
      "  0.5061\n",
      "  0.4166\n",
      "  0.2027\n",
      "  1.1202\n",
      "  0.9134\n",
      "  0.6500\n",
      "  0.9310\n",
      "  0.1543\n",
      "  0.6064\n",
      "  0.4601\n",
      "  0.8077\n",
      "  0.4324\n",
      "  0.6722\n",
      "  0.1460\n",
      "  0.6274\n",
      "  0.3124\n",
      "  0.4643\n",
      "  0.7515\n",
      "  0.0745\n",
      "  0.9471\n",
      "  0.8134\n",
      "  0.3300\n",
      "  0.5231\n",
      "  0.7472\n",
      "  0.4664\n",
      "  0.9025\n",
      "  0.3407\n",
      "  0.3941\n",
      "  0.3472\n",
      "  0.2645\n",
      "  0.4397\n",
      "  0.4302\n",
      "  0.6278\n",
      "  0.7422\n",
      "  1.3372\n",
      "  0.4326\n",
      "  0.5871\n",
      "  0.7917\n",
      "  0.8178\n",
      "  0.8979\n",
      "  0.8072\n",
      "  1.1161\n",
      "  0.2407\n",
      "  0.6624\n",
      "  1.1433\n",
      "  0.3885\n",
      "  0.9585\n",
      "  0.9623\n",
      "  0.8124\n",
      "  0.9561\n",
      "  0.3423\n",
      "  0.5719\n",
      "  0.8379\n",
      "  0.8299\n",
      "  0.9092\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dummy_filter_ranks = {}\n",
    "\n",
    "if activation_index not in dummy_filter_ranks:\n",
    "    dummy_filter_ranks[activation_index] = torch.FloatTensor(activation.size(1)).zero_().cuda()\n",
    "\n",
    "dummy_filter_ranks[activation_index] += values\n",
    "\n",
    "print(dummy_filter_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要度の順位付け、pruning対象となるフィルタの決定\n",
    "\n",
    "以上で計算した重要度を元に、重要度の最も低いフィルタをpruning対象とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規化\n",
    "\n",
    "`filter_ranks`のスケールが層によって異なるため、層ごとにL2正規化を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64,) [ -3.73500662e-08  -2.04436663e-08  -4.24422844e-08   1.50498369e-09\n",
      "  -1.22746599e-07]\n",
      "1 (64,) [ -6.03485262e-08   1.54667390e-08  -1.66291812e-07  -1.09614007e-09\n",
      "  -4.62700172e-08]\n",
      "2 (128,) [  7.49703801e-08   1.48712473e-07  -2.28549837e-07  -1.70827221e-07\n",
      "  -3.12936493e-07]\n",
      "3 (128,) [  5.78968269e-08  -3.95947012e-07  -3.97092407e-07   3.17554111e-07\n",
      "   7.05701497e-09]\n",
      "4 (256,) [  8.22116363e-07  -1.80695736e-07  -2.16293529e-07   1.20318447e-07\n",
      "  -2.78650667e-08]\n",
      "5 (256,) [ -1.88000655e-07  -7.05653406e-07  -1.78253941e-07  -2.87118553e-07\n",
      "   1.47676253e-08]\n",
      "6 (256,) [ -1.84796690e-07  -2.70328258e-07  -2.81789852e-07  -1.09626865e-06\n",
      "  -3.09229421e-07]\n",
      "7 (512,) [  6.66967253e-07  -7.56142185e-07  -1.35905026e-07  -1.18118214e-06\n",
      "  -5.31615513e-07]\n",
      "8 (512,) [  4.30816698e-07  -1.79872245e-07  -4.61390755e-06  -1.18717526e-06\n",
      "   5.99207453e-07]\n",
      "9 (512,) [ -3.60778495e-06  -5.40017879e-07   1.03791353e-06  -3.20131051e-07\n",
      "  -1.15264629e-06]\n",
      "10 (512,) [  1.43056968e-06   3.65088681e-07   1.32466744e-06   1.52440680e-06\n",
      "   7.40145481e-07]\n",
      "11 (512,) [ -1.31713296e-06  -1.48420531e-06  -2.14270813e-06   2.85565147e-06\n",
      "   6.38635015e-07]\n",
      "12 (512,) [ -1.42886040e-06   1.03877551e-06   1.62380638e-06  -1.57919458e-05\n",
      "  -4.68435815e-08]\n",
      "0 (64,) [ 0.08107772  0.04437812  0.09213166]\n",
      "1 (64,) [ 0.08513896  0.02182029  0.23460245]\n",
      "2 (128,) [ 0.04396948  0.08721858  0.1340425 ]\n",
      "3 (128,) [ 0.02395755  0.16384177  0.16431573]\n",
      "4 (256,) [ 0.1167329   0.02565712  0.03071168]\n",
      "5 (256,) [ 0.02927743  0.10989174  0.02775957]\n",
      "6 (256,) [ 0.02260715  0.03307068  0.03447284]\n",
      "7 (512,) [ 0.02257662  0.02559516  0.00460034]\n",
      "8 (512,) [ 0.01567003  0.00654247  0.16782098]\n",
      "9 (512,) [ 0.12854864  0.01924132  0.03698179]\n",
      "10 (512,) [ 0.00873688  0.0022297   0.00809011]\n",
      "11 (512,) [ 0.00865989  0.00975835  0.01408788]\n",
      "12 (512,) [ 0.01453915  0.0105699   0.01652279]\n"
     ]
    }
   ],
   "source": [
    "# before normalization\n",
    "for i in filter_ranks:\n",
    "    f = filter_ranks[i].cpu().numpy()\n",
    "    print(i, f.shape, f[:5])\n",
    "\n",
    "# normalize_ranks_per_layer()\n",
    "for i in filter_ranks:\n",
    "    v = torch.abs(filter_ranks[i])\n",
    "    v = v / np.sqrt(torch.sum(v * v))\n",
    "    filter_ranks[i] = v.cpu()\n",
    "\n",
    "# after normalization\n",
    "for i in filter_ranks:\n",
    "    f = filter_ranks[i].cpu().numpy()\n",
    "    print(i, f.shape, f[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要度の最も小さいフィルタをn枚抽出する\n",
    "\n",
    "全ての層から、重要度の最も小さいフィルタを集めて以下の形式のリストにします。\n",
    "- (層番号，フィルタ番号，フィルタの重要度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "256\n",
      "(21, 40, 1.0759843682706105e-08)\n",
      "(17, 78, 5.7456950344203506e-06)\n",
      "(24, 161, 6.677765668428037e-06)\n",
      "(28, 258, 1.5789490134920925e-05)\n",
      "(24, 137, 2.9008037017774768e-05)\n"
     ]
    }
   ],
   "source": [
    "# number of filters prunned\n",
    "num = 256\n",
    "\n",
    "data = []\n",
    "for i in sorted(filter_ranks.keys()):\n",
    "    for j in range(filter_ranks[i].size(0)):\n",
    "        data.append((activation_to_layer[i], j, filter_ranks[i][j]))\n",
    "\n",
    "filters_to_prune = nsmallest(num, data, itemgetter(2))\n",
    "\n",
    "print(filters_to_prune.__class__)\n",
    "print(len(filters_to_prune))\n",
    "for i in range(5):\n",
    "    print(filters_to_prune[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heapq.nsmallest(n, iterable, key=None)\n",
    "\n",
    "https://docs.python.jp/3/library/heapq.html\n",
    "\n",
    ">iterable で定義されるデータセットのうち、最小値から昇順に n 個の値のリストを返します。\n",
    ">(あたえられた場合) key は、引数を一つとる、iterable のそれぞれの要素から比較キーを生成する関数を指定します: key=str.lower 以下のコードと同等です: sorted(iterable, key=key)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### key: 全体での層番号、value: pruning対象のフィルタ番号の辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 :  1 filters,  [45]\n",
      "layer 2 :  1 filters,  [3]\n",
      "layer 5 :  1 filters,  [70]\n",
      "layer 7 :  4 filters,  [99, 88, 22, 14]\n",
      "layer 10 :  11 filters,  [128, 209, 138, 28, 197, 123, 236, 169, 119, 87, 52]\n",
      "layer 12 :  7 filters,  [235, 181, 118, 105, 23, 27, 80]\n",
      "layer 14 :  9 filters,  [233, 41, 185, 248, 111, 168, 25, 255, 18]\n",
      "layer 17 :  24 filters,  [78, 457, 277, 301, 502, 308, 181, 318, 102, 136, 418, 270, 280, 267, 461, 266, 53, 192, 295, 463, 432, 323, 419, 333]\n",
      "layer 19 :  21 filters,  [130, 222, 347, 377, 118, 380, 122, 7, 293, 73, 438, 353, 124, 382, 306, 11, 83, 114, 419, 92, 64]\n",
      "layer 21 :  20 filters,  [40, 22, 290, 112, 75, 175, 212, 131, 176, 111, 361, 291, 437, 504, 510, 276, 299, 115, 419, 355]\n",
      "layer 24 :  41 filters,  [161, 137, 276, 333, 211, 192, 219, 467, 500, 393, 203, 28, 317, 438, 490, 248, 135, 351, 99, 205, 160, 101, 238, 230, 171, 66, 95, 97, 156, 222, 167, 29, 433, 272, 266, 252, 408, 322, 382, 198, 414]\n",
      "layer 26 :  41 filters,  [53, 239, 33, 238, 77, 335, 404, 349, 122, 429, 234, 247, 343, 299, 72, 483, 507, 387, 319, 459, 256, 504, 126, 276, 219, 508, 304, 435, 191, 422, 106, 392, 31, 82, 177, 272, 379, 418, 370, 380, 26]\n",
      "layer 28 :  75 filters,  [258, 70, 410, 63, 300, 302, 496, 91, 199, 426, 64, 170, 347, 324, 315, 383, 247, 492, 81, 221, 289, 4, 276, 263, 381, 380, 9, 46, 240, 103, 241, 351, 139, 174, 101, 404, 464, 166, 334, 297, 415, 355, 412, 106, 99, 224, 69, 197, 366, 147, 44, 331, 74, 235, 29, 344, 98, 100, 88, 271, 8, 277, 357, 203, 397, 234, 330, 83, 471, 142, 176, 431, 354, 78, 447]\n"
     ]
    }
   ],
   "source": [
    "filters_to_prune_per_layer = {}\n",
    "for (l, f, _) in filters_to_prune:\n",
    "    if l not in filters_to_prune_per_layer:\n",
    "        filters_to_prune_per_layer[l] = []\n",
    "    filters_to_prune_per_layer[l].append(f)\n",
    "\n",
    "for i in sorted(filters_to_prune_per_layer.items()):\n",
    "    print(\"layer\", i[0],   \": \", len(i[1]), \"filters, \", i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 削除後のインデックスを考慮して、フィルタ番号を振り直す\n",
    "\n",
    "例）フィルタ削除の順番が「0->24->30」だったとします。\n",
    "0番を削除した場合、第24番、第30番のフィルタはそれぞれ第23番、第29番になります。\n",
    "次に第23番のフィルタを削除した場合、第29番のフィルタは第28番になります。\n",
    "よって，番号を0, 23, 28と振り直します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 :  1 filters,  [45]\n",
      "layer 2 :  1 filters,  [3]\n",
      "layer 5 :  1 filters,  [70]\n",
      "layer 7 :  4 filters,  [14, 21, 86, 96]\n",
      "layer 10 :  11 filters,  [28, 51, 85, 116, 119, 123, 132, 162, 189, 200, 226]\n",
      "layer 12 :  7 filters,  [23, 26, 78, 102, 114, 176, 229]\n",
      "layer 14 :  9 filters,  [18, 24, 39, 108, 164, 180, 227, 241, 247]\n",
      "layer 17 :  24 filters,  [53, 77, 100, 133, 177, 187, 260, 260, 262, 268, 270, 284, 289, 295, 304, 308, 317, 401, 401, 413, 437, 440, 441, 479]\n",
      "layer 19 :  21 filters,  [7, 10, 62, 70, 79, 87, 108, 111, 114, 115, 120, 211, 281, 293, 333, 338, 361, 363, 364, 400, 418]\n",
      "layer 21 :  20 filters,  [22, 39, 73, 108, 108, 110, 125, 168, 168, 203, 266, 279, 279, 286, 341, 346, 403, 420, 486, 491]\n",
      "layer 24 :  41 filters,  [28, 28, 64, 92, 93, 94, 95, 128, 129, 147, 150, 150, 155, 158, 178, 183, 187, 188, 193, 200, 202, 209, 216, 225, 228, 241, 246, 249, 289, 293, 303, 320, 350, 360, 374, 379, 397, 401, 429, 451, 460]\n",
      "layer 26 :  41 filters,  [26, 30, 31, 50, 68, 72, 76, 99, 114, 117, 167, 180, 207, 221, 224, 224, 231, 239, 254, 257, 279, 283, 297, 312, 319, 324, 344, 352, 352, 358, 362, 373, 386, 389, 395, 400, 423, 446, 466, 468, 468]\n",
      "layer 28 :  75 filters,  [4, 7, 7, 26, 40, 41, 57, 57, 61, 61, 64, 67, 69, 70, 74, 76, 82, 82, 82, 82, 83, 85, 117, 119, 123, 141, 144, 147, 148, 168, 169, 172, 189, 191, 200, 200, 204, 204, 209, 219, 223, 230, 234, 234, 245, 252, 254, 255, 267, 275, 280, 280, 282, 291, 293, 296, 298, 298, 299, 307, 320, 320, 321, 334, 340, 345, 346, 348, 358, 362, 377, 393, 399, 419, 422]\n"
     ]
    }
   ],
   "source": [
    "for l in filters_to_prune_per_layer:\n",
    "    filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
    "    for i in range(len(filters_to_prune_per_layer[l])):\n",
    "        filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
    "\n",
    "for i in sorted(filters_to_prune_per_layer.items()):\n",
    "    print(\"layer\", i[0],   \": \", len(i[1]), \"filters, \", i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (層番号, フィルタ番号)のリストに直す\n",
    "これでpruningの準備は完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 45),\n",
       " (2, 3),\n",
       " (5, 70),\n",
       " (7, 14),\n",
       " (7, 21),\n",
       " (7, 86),\n",
       " (7, 96),\n",
       " (10, 28),\n",
       " (10, 51),\n",
       " (10, 85),\n",
       " (10, 116),\n",
       " (10, 119),\n",
       " (10, 123),\n",
       " (10, 132),\n",
       " (10, 162),\n",
       " (10, 189),\n",
       " (10, 200),\n",
       " (10, 226),\n",
       " (12, 23),\n",
       " (12, 26),\n",
       " (12, 78),\n",
       " (12, 102),\n",
       " (12, 114),\n",
       " (12, 176),\n",
       " (12, 229),\n",
       " (14, 18),\n",
       " (14, 24),\n",
       " (14, 39),\n",
       " (14, 108),\n",
       " (14, 164),\n",
       " (14, 180),\n",
       " (14, 227),\n",
       " (14, 241),\n",
       " (14, 247),\n",
       " (17, 53),\n",
       " (17, 77),\n",
       " (17, 100),\n",
       " (17, 133),\n",
       " (17, 177),\n",
       " (17, 187),\n",
       " (17, 260),\n",
       " (17, 260),\n",
       " (17, 262),\n",
       " (17, 268),\n",
       " (17, 270),\n",
       " (17, 284),\n",
       " (17, 289),\n",
       " (17, 295),\n",
       " (17, 304),\n",
       " (17, 308),\n",
       " (17, 317),\n",
       " (17, 401),\n",
       " (17, 401),\n",
       " (17, 413),\n",
       " (17, 437),\n",
       " (17, 440),\n",
       " (17, 441),\n",
       " (17, 479),\n",
       " (19, 7),\n",
       " (19, 10),\n",
       " (19, 62),\n",
       " (19, 70),\n",
       " (19, 79),\n",
       " (19, 87),\n",
       " (19, 108),\n",
       " (19, 111),\n",
       " (19, 114),\n",
       " (19, 115),\n",
       " (19, 120),\n",
       " (19, 211),\n",
       " (19, 281),\n",
       " (19, 293),\n",
       " (19, 333),\n",
       " (19, 338),\n",
       " (19, 361),\n",
       " (19, 363),\n",
       " (19, 364),\n",
       " (19, 400),\n",
       " (19, 418),\n",
       " (21, 22),\n",
       " (21, 39),\n",
       " (21, 73),\n",
       " (21, 108),\n",
       " (21, 108),\n",
       " (21, 110),\n",
       " (21, 125),\n",
       " (21, 168),\n",
       " (21, 168),\n",
       " (21, 203),\n",
       " (21, 266),\n",
       " (21, 279),\n",
       " (21, 279),\n",
       " (21, 286),\n",
       " (21, 341),\n",
       " (21, 346),\n",
       " (21, 403),\n",
       " (21, 420),\n",
       " (21, 486),\n",
       " (21, 491),\n",
       " (24, 28),\n",
       " (24, 28),\n",
       " (24, 64),\n",
       " (24, 92),\n",
       " (24, 93),\n",
       " (24, 94),\n",
       " (24, 95),\n",
       " (24, 128),\n",
       " (24, 129),\n",
       " (24, 147),\n",
       " (24, 150),\n",
       " (24, 150),\n",
       " (24, 155),\n",
       " (24, 158),\n",
       " (24, 178),\n",
       " (24, 183),\n",
       " (24, 187),\n",
       " (24, 188),\n",
       " (24, 193),\n",
       " (24, 200),\n",
       " (24, 202),\n",
       " (24, 209),\n",
       " (24, 216),\n",
       " (24, 225),\n",
       " (24, 228),\n",
       " (24, 241),\n",
       " (24, 246),\n",
       " (24, 249),\n",
       " (24, 289),\n",
       " (24, 293),\n",
       " (24, 303),\n",
       " (24, 320),\n",
       " (24, 350),\n",
       " (24, 360),\n",
       " (24, 374),\n",
       " (24, 379),\n",
       " (24, 397),\n",
       " (24, 401),\n",
       " (24, 429),\n",
       " (24, 451),\n",
       " (24, 460),\n",
       " (26, 26),\n",
       " (26, 30),\n",
       " (26, 31),\n",
       " (26, 50),\n",
       " (26, 68),\n",
       " (26, 72),\n",
       " (26, 76),\n",
       " (26, 99),\n",
       " (26, 114),\n",
       " (26, 117),\n",
       " (26, 167),\n",
       " (26, 180),\n",
       " (26, 207),\n",
       " (26, 221),\n",
       " (26, 224),\n",
       " (26, 224),\n",
       " (26, 231),\n",
       " (26, 239),\n",
       " (26, 254),\n",
       " (26, 257),\n",
       " (26, 279),\n",
       " (26, 283),\n",
       " (26, 297),\n",
       " (26, 312),\n",
       " (26, 319),\n",
       " (26, 324),\n",
       " (26, 344),\n",
       " (26, 352),\n",
       " (26, 352),\n",
       " (26, 358),\n",
       " (26, 362),\n",
       " (26, 373),\n",
       " (26, 386),\n",
       " (26, 389),\n",
       " (26, 395),\n",
       " (26, 400),\n",
       " (26, 423),\n",
       " (26, 446),\n",
       " (26, 466),\n",
       " (26, 468),\n",
       " (26, 468),\n",
       " (28, 4),\n",
       " (28, 7),\n",
       " (28, 7),\n",
       " (28, 26),\n",
       " (28, 40),\n",
       " (28, 41),\n",
       " (28, 57),\n",
       " (28, 57),\n",
       " (28, 61),\n",
       " (28, 61),\n",
       " (28, 64),\n",
       " (28, 67),\n",
       " (28, 69),\n",
       " (28, 70),\n",
       " (28, 74),\n",
       " (28, 76),\n",
       " (28, 82),\n",
       " (28, 82),\n",
       " (28, 82),\n",
       " (28, 82),\n",
       " (28, 83),\n",
       " (28, 85),\n",
       " (28, 117),\n",
       " (28, 119),\n",
       " (28, 123),\n",
       " (28, 141),\n",
       " (28, 144),\n",
       " (28, 147),\n",
       " (28, 148),\n",
       " (28, 168),\n",
       " (28, 169),\n",
       " (28, 172),\n",
       " (28, 189),\n",
       " (28, 191),\n",
       " (28, 200),\n",
       " (28, 200),\n",
       " (28, 204),\n",
       " (28, 204),\n",
       " (28, 209),\n",
       " (28, 219),\n",
       " (28, 223),\n",
       " (28, 230),\n",
       " (28, 234),\n",
       " (28, 234),\n",
       " (28, 245),\n",
       " (28, 252),\n",
       " (28, 254),\n",
       " (28, 255),\n",
       " (28, 267),\n",
       " (28, 275),\n",
       " (28, 280),\n",
       " (28, 280),\n",
       " (28, 282),\n",
       " (28, 291),\n",
       " (28, 293),\n",
       " (28, 296),\n",
       " (28, 298),\n",
       " (28, 298),\n",
       " (28, 299),\n",
       " (28, 307),\n",
       " (28, 320),\n",
       " (28, 320),\n",
       " (28, 321),\n",
       " (28, 334),\n",
       " (28, 340),\n",
       " (28, 345),\n",
       " (28, 346),\n",
       " (28, 348),\n",
       " (28, 358),\n",
       " (28, 362),\n",
       " (28, 377),\n",
       " (28, 393),\n",
       " (28, 399),\n",
       " (28, 419),\n",
       " (28, 422)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_targets = []\n",
    "for l in filters_to_prune_per_layer:\n",
    "    for i in filters_to_prune_per_layer[l]:\n",
    "        prune_targets.append((l, i))\n",
    "\n",
    "print(len(prune_targets))\n",
    "prune_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フィルタをpruningして新たなモデルを作成する\n",
    "\n",
    "`prune.py`の`prune_vgg16_conv_layer`は、モデルからフィルタを1枚削除した新しいモデルを返す関数です。\n",
    "これをfor分で上記で指定したpruning枚数分(ここでは256枚分)繰り返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers that will be prunned {0: 1, 2: 1, 5: 1, 7: 4, 10: 11, 12: 7, 14: 9, 17: 24, 19: 21, 21: 20, 24: 41, 26: 41, 28: 75}\n",
      "Prunning filters.. \n",
      "0 45\n",
      "2 3\n",
      "5 70\n",
      "7 14\n",
      "7 21\n",
      "7 86\n",
      "7 96\n",
      "10 28\n",
      "10 51\n",
      "10 85\n",
      "10 116\n",
      "10 119\n",
      "10 123\n",
      "10 132\n",
      "10 162\n",
      "10 189\n",
      "10 200\n",
      "10 226\n",
      "12 23\n",
      "12 26\n",
      "12 78\n",
      "12 102\n",
      "12 114\n",
      "12 176\n",
      "12 229\n",
      "14 18\n",
      "14 24\n",
      "14 39\n",
      "14 108\n",
      "14 164\n",
      "14 180\n",
      "14 227\n",
      "14 241\n",
      "14 247\n",
      "17 53\n",
      "17 77\n",
      "17 100\n",
      "17 133\n",
      "17 177\n",
      "17 187\n",
      "17 260\n",
      "17 260\n",
      "17 262\n",
      "17 268\n",
      "17 270\n",
      "17 284\n",
      "17 289\n",
      "17 295\n",
      "17 304\n",
      "17 308\n",
      "17 317\n",
      "17 401\n",
      "17 401\n",
      "17 413\n",
      "17 437\n",
      "17 440\n",
      "17 441\n",
      "17 479\n",
      "19 7\n",
      "19 10\n",
      "19 62\n",
      "19 70\n",
      "19 79\n",
      "19 87\n",
      "19 108\n",
      "19 111\n",
      "19 114\n",
      "19 115\n",
      "19 120\n",
      "19 211\n",
      "19 281\n",
      "19 293\n",
      "19 333\n",
      "19 338\n",
      "19 361\n",
      "19 363\n",
      "19 364\n",
      "19 400\n",
      "19 418\n",
      "21 22\n",
      "21 39\n",
      "21 73\n",
      "21 108\n",
      "21 108\n",
      "21 110\n",
      "21 125\n",
      "21 168\n",
      "21 168\n",
      "21 203\n",
      "21 266\n",
      "21 279\n",
      "21 279\n",
      "21 286\n",
      "21 341\n",
      "21 346\n",
      "21 403\n",
      "21 420\n",
      "21 486\n",
      "21 491\n",
      "24 28\n",
      "24 28\n",
      "24 64\n",
      "24 92\n",
      "24 93\n",
      "24 94\n",
      "24 95\n",
      "24 128\n",
      "24 129\n",
      "24 147\n",
      "24 150\n",
      "24 150\n",
      "24 155\n",
      "24 158\n",
      "24 178\n",
      "24 183\n",
      "24 187\n",
      "24 188\n",
      "24 193\n",
      "24 200\n",
      "24 202\n",
      "24 209\n",
      "24 216\n",
      "24 225\n",
      "24 228\n",
      "24 241\n",
      "24 246\n",
      "24 249\n",
      "24 289\n",
      "24 293\n",
      "24 303\n",
      "24 320\n",
      "24 350\n",
      "24 360\n",
      "24 374\n",
      "24 379\n",
      "24 397\n",
      "24 401\n",
      "24 429\n",
      "24 451\n",
      "24 460\n",
      "26 26\n",
      "26 30\n",
      "26 31\n",
      "26 50\n",
      "26 68\n",
      "26 72\n",
      "26 76\n",
      "26 99\n",
      "26 114\n",
      "26 117\n",
      "26 167\n",
      "26 180\n",
      "26 207\n",
      "26 221\n",
      "26 224\n",
      "26 224\n",
      "26 231\n",
      "26 239\n",
      "26 254\n",
      "26 257\n",
      "26 279\n",
      "26 283\n",
      "26 297\n",
      "26 312\n",
      "26 319\n",
      "26 324\n",
      "26 344\n",
      "26 352\n",
      "26 352\n",
      "26 358\n",
      "26 362\n",
      "26 373\n",
      "26 386\n",
      "26 389\n",
      "26 395\n",
      "26 400\n",
      "26 423\n",
      "26 446\n",
      "26 466\n",
      "26 468\n",
      "26 468\n",
      "28 4\n",
      "28 7\n",
      "28 7\n",
      "28 26\n",
      "28 40\n",
      "28 41\n",
      "28 57\n",
      "28 57\n",
      "28 61\n",
      "28 61\n",
      "28 64\n",
      "28 67\n",
      "28 69\n",
      "28 70\n",
      "28 74\n",
      "28 76\n",
      "28 82\n",
      "28 82\n",
      "28 82\n",
      "28 82\n",
      "28 83\n",
      "28 85\n",
      "28 117\n",
      "28 119\n",
      "28 123\n",
      "28 141\n",
      "28 144\n",
      "28 147\n",
      "28 148\n",
      "28 168\n",
      "28 169\n",
      "28 172\n",
      "28 189\n",
      "28 191\n",
      "28 200\n",
      "28 200\n",
      "28 204\n",
      "28 204\n",
      "28 209\n",
      "28 219\n",
      "28 223\n",
      "28 230\n",
      "28 234\n",
      "28 234\n",
      "28 245\n",
      "28 252\n",
      "28 254\n",
      "28 255\n",
      "28 267\n",
      "28 275\n",
      "28 280\n",
      "28 280\n",
      "28 282\n",
      "28 291\n",
      "28 293\n",
      "28 296\n",
      "28 298\n",
      "28 298\n",
      "28 299\n",
      "28 307\n",
      "28 320\n",
      "28 320\n",
      "28 321\n",
      "28 334\n",
      "28 340\n",
      "28 345\n",
      "28 346\n",
      "28 348\n",
      "28 358\n",
      "28 362\n",
      "28 377\n",
      "28 393\n",
      "28 399\n",
      "28 419\n",
      "28 422\n"
     ]
    }
   ],
   "source": [
    "layers_prunned = {}\n",
    "for layer_index, filter_index in prune_targets:\n",
    "    if layer_index not in layers_prunned:\n",
    "        layers_prunned[layer_index] = 0\n",
    "    layers_prunned[layer_index] = layers_prunned[layer_index] + 1 \n",
    "\n",
    "print(\"Layers that will be prunned\", layers_prunned)\n",
    "print(\"Prunning filters.. \")\n",
    "prunned_model = model.cpu()\n",
    "\n",
    "for layer_index, filter_index in prune_targets:\n",
    "    print(layer_index, filter_index)\n",
    "    prunned_model = prune_vgg16_conv_layer(model, layer_index, filter_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pruning前後のモデルのチャンネル数を比較する\n",
    "\n",
    "#### pruning前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prunned_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-7bda266c5198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mafter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprunned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prunned_model' is not defined"
     ]
    }
   ],
   "source": [
    "before = model.features._modules\n",
    "after = prunned_model.features._modules\n",
    "for i in range(len(before)):\n",
    "    print(i, before[str(i)])\n",
    "    print(i, after[str(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論テスト\n",
    "最後に、pruning前後での推論の精度と実行時間を比較します。\n",
    "今回はfine-tuningを行っていないため、pruning後は精度が落ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.94125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModifiedVGG16Model (\n",
       "  (features): Sequential (\n",
       "    (0): Conv2d(3, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Conv2d(61, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU (inplace)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (5): Conv2d(61, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU (inplace)\n",
       "    (7): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU (inplace)\n",
       "    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (10): Conv2d(124, 242, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU (inplace)\n",
       "    (12): Conv2d(242, 249, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU (inplace)\n",
       "    (14): Conv2d(249, 251, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU (inplace)\n",
       "    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (17): Conv2d(251, 481, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU (inplace)\n",
       "    (19): Conv2d(481, 489, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU (inplace)\n",
       "    (21): Conv2d(489, 483, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU (inplace)\n",
       "    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (24): Conv2d(483, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU (inplace)\n",
       "    (26): Conv2d(486, 473, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU (inplace)\n",
       "    (28): Conv2d(473, 444, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU (inplace)\n",
       "    (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential (\n",
       "    (0): Dropout (p = 0.5)\n",
       "    (1): Linear (21756 -> 4096)\n",
       "    (2): ReLU (inplace)\n",
       "    (3): Dropout (p = 0.5)\n",
       "    (4): Linear (4096 -> 4096)\n",
       "    (5): ReLU (inplace)\n",
       "    (6): Linear (4096 -> 2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before pruning\n",
    "model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for i, (batch, label) in enumerate(test_data_loader):\n",
    "    batch = batch.cuda()\n",
    "    output = model(Variable(batch))\n",
    "    pred = output.data.max(1)[1]\n",
    "    correct += pred.cpu().eq(label).sum()\n",
    "    total += label.size(0)\n",
    "\n",
    "print(\"Accuracy :\", float(correct) / total)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after pruning\n",
    "model = prunned_model.cuda()\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for i, (batch, label) in enumerate(test_data_loader):\n",
    "    batch = batch.cuda()\n",
    "    output = model(Variable(batch))\n",
    "    pred = output.data.max(1)[1]\n",
    "    correct += pred.cpu().eq(label).sum()\n",
    "    total += label.size(0)\n",
    "\n",
    "print(\"Accuracy :\", float(correct) / total)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
